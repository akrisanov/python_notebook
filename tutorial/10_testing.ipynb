{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Pros:\n",
    "- Tests check code correctness\n",
    "- Tests help to refactor without fear\n",
    "\n",
    "Cons:\n",
    "- It takes time to write good tests\n",
    "- Tests > code\n",
    "- Working tests don't guarantee the correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle(iterable):\n",
    "    \"\"\"Applies run-length encoding to an iterable.\"\"\"\n",
    "    for item, g in itertools.groupby(iterable):\n",
    "        yield item, sum(1 for _ in g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('m', 1),\n",
       " ('i', 1),\n",
       " ('s', 2),\n",
       " ('i', 1),\n",
       " ('s', 2),\n",
       " ('i', 1),\n",
       " ('p', 2),\n",
       " ('i', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rle(\"mississippi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doctests\n",
    "\n",
    "- [doctest ‚Äî Test interactive Python examples](https://docs.python.org/3/library/doctest.html)\n",
    "- [doctest ‚Äî Testing Through Documentation](https://pymotw.com/3/doctest/)\n",
    "\n",
    "Pros:\n",
    "- Included in the standard library\n",
    "- Help to test small projects and pieces of code\n",
    "- Easy to read\n",
    "- Serve as examples of usage\n",
    "\n",
    "Cons:\n",
    "- Assertion works only with a string representation of result\n",
    "- Long doctests make documentation hard to read\n",
    "- No standard way to run subsets of doctests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle(iterable):\n",
    "    \"\"\"Applies run-length encoding to an iterable.\n",
    "    \n",
    "    >>> list(rle(\"\"))\n",
    "    []\n",
    "    >>> list(rle(\"mississippi\"))\n",
    "    [('m', 1), ('i', 1), ('s', 2), ('i', 1),\n",
    "     ('s', 2), ('i', 1), ('p', 2), ('i', 1)]\n",
    "    \"\"\"\n",
    "    for item, g in itertools.groupby(iterable):\n",
    "        yield item, sum(1 for _ in g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"__main__\", line 6, in __main__.rle\n",
      "Failed example:\n",
      "    list(rle(\"mississippi\"))\n",
      "Expected:\n",
      "    [('m', 1), ('i', 1), ('s', 2), ('i', 1),\n",
      "     ('s', 2), ('i', 1), ('p', 2), ('i', 1)]\n",
      "Got:\n",
      "    [('m', 1), ('i', 1), ('s', 2), ('i', 1), ('s', 2), ('i', 1), ('p', 2), ('i', 1)]\n",
      "**********************************************************************\n",
      "1 items had failures:\n",
      "   1 of   2 in __main__.rle\n",
      "***Test Failed*** 1 failures.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the problem with a new line character we can use the doctest [directives](https://docs.python.org/3/library/doctest.html#directives), for example:\n",
    "\n",
    "```python\n",
    "# doctest: +NORMALIZE_WHITESPACE\n",
    "# doctest: +ELLIPSIS\n",
    "```\n",
    "\n",
    "[Working Around Whitespace](https://pymotw.com/3/doctest/#working-around-whitespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assertions\n",
    "\n",
    "The `assert` operator is easy to use, but it has some drawbacks:\n",
    "- Tests need to be run manually\n",
    "- Difficult to debug\n",
    "- Hard to understand the failures if no error message has been provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "42",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5799a4817d38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: 42"
     ]
    }
   ],
   "source": [
    "assert [], 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad test\n",
    "def test_rle():\n",
    "    s = \"mississippi\"\n",
    "    tmp = set(ch for ch, _count in rle(s))\n",
    "    assert tmp == set(s[:-1] + s[1])\n",
    "    assert not list(rle(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good tests\n",
    "def test_rle():\n",
    "    assert rle(\"mississippi\") == [\n",
    "        ('m', 1), ('i', 1), ('s', 2), ('i', 1), \n",
    "        ('s', 2), ('i', 1), ('p', 2), ('i', 1)\n",
    "    ]\n",
    "\n",
    "\n",
    "def test_rle_empty():\n",
    "    assert not list(rle(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d956dada0712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_rle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-0e228a8c3da8>\u001b[0m in \u001b[0;36mtest_rle\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     assert rle(\"mississippi\") == [\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     ]\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_rle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rle_empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è AssertErrors are hard to read and understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even better test\n",
    "def test_rle():\n",
    "    actual = rle(\"mississippi\")\n",
    "    expected = [\n",
    "        ('m', 1), ('i', 1), ('s', 2), ('i', 1), \n",
    "        ('s', 2), ('i', 1), ('p', 2), ('i', 1)\n",
    "    ]\n",
    "    message = f\"{actual} != {expected}\"\n",
    "    assert actual == expected, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "<generator object rle at 0x1044eb050> != [('m', 1), ('i', 1), ('s', 2), ('i', 1), ('s', 2), ('i', 1), ('p', 2), ('i', 1)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d956dada0712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_rle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-dae36437d366>\u001b[0m in \u001b[0;36mtest_rle\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     ]\n\u001b[1;32m      8\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{actual} != {expected}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: <generator object rle at 0x1044eb050> != [('m', 1), ('i', 1), ('s', 2), ('i', 1), ('s', 2), ('i', 1), ('p', 2), ('i', 1)]"
     ]
    }
   ],
   "source": [
    "test_rle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^^ Now we can understand the failed test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `unittest` module\n",
    "\n",
    "- [unittest ‚Äî Unit testing framework](https://docs.python.org/3/library/unittest.html)\n",
    "- [Getting Started With Testing in Python](https://realpython.com/python-testing/)\n",
    "\n",
    "Pros:\n",
    "- Included in the standard library\n",
    "- Shows readable error messages\n",
    "- Has a test runner\n",
    "\n",
    "Cons:\n",
    "- Java-like API with classes\n",
    "- Tests are verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# test_rle.py\n",
    "\n",
    "import unittest\n",
    "from rle import rle\n",
    "\n",
    "\n",
    "class TestRLE(unittest.TestCase):\n",
    "    def test_rle(self):\n",
    "        self.assertEqual(\n",
    "            rle(\"mississippi\"),\n",
    "            [\n",
    "                (\"m\", 1),\n",
    "                (\"i\", 1),\n",
    "                (\"s\", 2),\n",
    "                (\"i\", 1),\n",
    "                (\"s\", 2),\n",
    "                (\"i\", 1),\n",
    "                (\"p\", 2),\n",
    "                (\"i\", 1),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def test_rle_empty(self):\n",
    "        self.assertEqual(list(rle(\"\")), [])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F.\r\n",
      "======================================================================\r\n",
      "FAIL: test_rle (__main__.TestRLE)\r\n",
      "----------------------------------------------------------------------\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"assets/test_rle.py\", line 17, in test_rle\r\n",
      "    (\"i\", 1),\r\n",
      "AssertionError: <generator object rle at 0x101c919b0> != [('m', 1), ('i', 1), ('s', 2), ('i', 1), ('s', 2), ('i', 1), ('p', 2), ('i', 1)]\r\n",
      "\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 2 tests in 0.000s\r\n",
      "\r\n",
      "FAILED (failures=1)\r\n"
     ]
    }
   ],
   "source": [
    "! python assets/test_rle.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running only some subset of test cases\n",
    "    \n",
    "```python\n",
    "suite = unittest.TestSuite([\n",
    "    TestRLE(),\n",
    "    TestSomethingElse(),\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all available tests\n",
    "\n",
    "\n",
    "```shell\n",
    "$ python -m unittest .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assertAlmostEqual',\n",
       " 'assertAlmostEquals',\n",
       " 'assertCountEqual',\n",
       " 'assertDictContainsSubset',\n",
       " 'assertDictEqual',\n",
       " 'assertEqual',\n",
       " 'assertEquals',\n",
       " 'assertFalse',\n",
       " 'assertGreater',\n",
       " 'assertGreaterEqual',\n",
       " 'assertIn',\n",
       " 'assertIs',\n",
       " 'assertIsInstance',\n",
       " 'assertIsNone',\n",
       " 'assertIsNot',\n",
       " 'assertIsNotNone',\n",
       " 'assertLess',\n",
       " 'assertLessEqual',\n",
       " 'assertListEqual',\n",
       " 'assertLogs',\n",
       " 'assertMultiLineEqual',\n",
       " 'assertNotAlmostEqual',\n",
       " 'assertNotAlmostEquals',\n",
       " 'assertNotEqual',\n",
       " 'assertNotEquals',\n",
       " 'assertNotIn',\n",
       " 'assertNotIsInstance',\n",
       " 'assertNotRegex',\n",
       " 'assertNotRegexpMatches',\n",
       " 'assertRaises',\n",
       " 'assertRaisesRegex',\n",
       " 'assertRaisesRegexp',\n",
       " 'assertRegex',\n",
       " 'assertRegexpMatches',\n",
       " 'assertSequenceEqual',\n",
       " 'assertSetEqual',\n",
       " 'assertTrue',\n",
       " 'assertTupleEqual',\n",
       " 'assertWarns',\n",
       " 'assertWarnsRegex',\n",
       " 'assert_']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unittest import TestCase\n",
    "import unittest\n",
    "[name for name in dir(TestCase) if name.startswith('assert')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `setUp` and `tearDown`\n",
    "\n",
    "\n",
    "[`setUp()`](https://docs.python.org/3/library/unittest.html#unittest.TestCase.setUp)\n",
    "\n",
    "> Method called to prepare the test fixture. This is called immediately before calling the test method; other than `AssertionError` or `SkipTest`, any exception raised by this method will be considered an error rather than a test failure. The default implementation does nothing.\n",
    "\n",
    "[`tearDown()`](https://docs.python.org/3/library/unittest.html#unittest.TestCase.tearDown)\n",
    "\n",
    "> Method called immediately after the test method has been called and the result recorded. This is called even if the test method raised an exception, so the implementation in subclasses may need to be particularly careful about checking internal state. Any exception, other than `AssertionError` or `SkipTest`, raised by this method will be considered an additional error rather than a test failure (thus increasing the total number of reported errors). This method will only be called if the `setUp()` succeeds, regardless of the outcome of the test method. The default implementation does nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `pytest` package\n",
    "\n",
    "üëâüèª [CheatSheet](https://github.com/akrisanov/python_notebook/blob/master/10_pytest.md)\n",
    "\n",
    "üß™ [Enough pytest to be Dangerous, 10 Things I Learned Writing Tests for 100 Python Exercises](https://pybit.es/pytest-coding-100-tests.html)\n",
    "\n",
    "Pros:\n",
    "- Don't need to learn a new API <= tests are usual functions\n",
    "- Convenient (readable) output\n",
    "- Parameterized tests\n",
    "- [Plugins](https://docs.pytest.org/en/latest/plugins.html)\n",
    "\n",
    "Cons:\n",
    "- Internal implementation is a pure magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "```python\n",
    "def test_rle():\n",
    "    assert rle(\"mississippi\") == [\n",
    "        (\"m\", 1),\n",
    "        (\"i\", 1),\n",
    "        (\"s\", 2),\n",
    "        (\"i\", 1),\n",
    "        (\"s\", 2),\n",
    "        (\"i\", 1),\n",
    "        (\"p\", 2),\n",
    "        (\"i\", 1),\n",
    "    ]\n",
    "\n",
    "\n",
    "def test_rle_empty():\n",
    "    assert not list(rle(\"\"))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Assertion introspection details](https://docs.pytest.org/en/latest/assert.html#assertion-introspection-details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                                                       [100%]\u001b[0m\r\n",
      "=================================== FAILURES ===================================\r\n",
      "\u001b[31m\u001b[1m___________________________________ test_rle ___________________________________\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m    def test_rle():\u001b[0m\r\n",
      "\u001b[1m>       assert rle(\"mississippi\") == [\u001b[0m\r\n",
      "\u001b[1m            (\"m\", 1),\u001b[0m\r\n",
      "\u001b[1m            (\"i\", 1),\u001b[0m\r\n",
      "\u001b[1m            (\"s\", 2),\u001b[0m\r\n",
      "\u001b[1m            (\"i\", 1),\u001b[0m\r\n",
      "\u001b[1m            (\"s\", 2),\u001b[0m\r\n",
      "\u001b[1m            (\"i\", 1),\u001b[0m\r\n",
      "\u001b[1m            (\"p\", 2),\u001b[0m\r\n",
      "\u001b[1m            (\"i\", 1),\u001b[0m\r\n",
      "\u001b[1m        ]\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert <generator ob...t 0x109530450> == [('m', 1), ('i...('i', 1), ...]\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE         -<generator object rle at 0x109530450>\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE         +[('m', 1), ('i', 1), ('s', 2), ('i', 1), ('s', 2), ('i', 1), ('p', 2), ('i', 1)]\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE         Full diff:\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE         - <generator object rle at 0x109530450>\u001b[0m\r\n",
      "\u001b[1m\u001b[31mE         + [('m', 1), ('i', 1), ('s', 2), ('i', 1), ('s', 2), ('i', 1), ('p', 2), ('i', 1)]\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m\u001b[31massets/test_py_rle.py\u001b[0m:6: AssertionError\r\n",
      "\u001b[31m\u001b[1m1 failed, 1 passed in 0.05 seconds\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! python3 -m pytest -q assets/test_py_rle.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametrizing tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "\n",
    "\n",
    "```python\n",
    "def cut_suffix(s, suffix):\n",
    "    return s[: s.rfind(suffix)]\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"s,suffix,expected\",\n",
    "    [\n",
    "        (\"foobar\", \"bar\", \"foo\"),\n",
    "        (\"foobar\", \"boo\", \"foobar\"),\n",
    "        (\"foobarbar\", \"bar\", \"foobar\"),\n",
    "    ],\n",
    ")\n",
    "def test_cust_suffix(s, suffix, expected):\n",
    "    assert cut_suffix(s, suffix) == expected\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                                                      [100%]\u001b[0m\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_____________________ test_cust_suffix[foobar-boo-foobar] ______________________\u001b[0m\n",
      "\n",
      "s = 'foobar', suffix = 'boo', expected = 'foobar'\n",
      "\n",
      "\u001b[1m    @pytest.mark.parametrize(\u001b[0m\n",
      "\u001b[1m        \"s,suffix,expected\",\u001b[0m\n",
      "\u001b[1m        [\u001b[0m\n",
      "\u001b[1m            (\"foobar\", \"bar\", \"foo\"),\u001b[0m\n",
      "\u001b[1m            (\"foobar\", \"boo\", \"foobar\"),\u001b[0m\n",
      "\u001b[1m            (\"foobarbar\", \"bar\", \"foobar\"),\u001b[0m\n",
      "\u001b[1m        ],\u001b[0m\n",
      "\u001b[1m    )\u001b[0m\n",
      "\u001b[1m    def test_cust_suffix(s, suffix, expected):\u001b[0m\n",
      "\u001b[1m>       assert cut_suffix(s, suffix) == expected\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 'fooba' == 'foobar'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         - fooba\u001b[0m\n",
      "\u001b[1m\u001b[31mE         + foobar\u001b[0m\n",
      "\u001b[1m\u001b[31mE         ?      +\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31massets/test_cut_suffix.py\u001b[0m:17: AssertionError\n",
      "\u001b[31m\u001b[1m1 failed, 2 passed in 0.07 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python3 -m pytest -q assets/test_cut_suffix.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixtures\n",
    "\n",
    "`setUp` and `tearDown` are alson exist in pytest, but more interesting feature of making fixtures is related to the following context definition:\n",
    "\n",
    "```python\n",
    "@pytest.yield_fixture\n",
    "def data(client):\n",
    "    resp = client.get(\"https://somewheaterdata.com/today.json\")\n",
    "    yield resp.body\n",
    "    client.close()\n",
    "\n",
    "    \n",
    "def test_print_wheather(data):\n",
    "    # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Hypothesis](https://hypothesis.readthedocs.io/en/latest/)\n",
    "\n",
    "> Hypothesis is a Python library for creating unit tests which are simpler to write and more powerful when run, finding edge cases in your code you wouldn‚Äôt have thought to look for. It is stable, powerful and easy to add to any existing test suite.\n",
    "\n",
    "- [Write Better Python with Hypothesis](https://medium.com/homeaway-tech-blog/write-better-python-with-hypothesis-5b31ac268b69)\n",
    "- [Unit Tests that Write Themselves: Property-based Testing using Hypothesis in Python](https://medium.com/@elliotchance/unit-tests-that-write-themselves-property-based-testing-using-hypothesis-in-python-62126631690d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
